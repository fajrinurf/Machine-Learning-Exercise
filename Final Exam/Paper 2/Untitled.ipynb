{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce796ed5-bf35-40b7-b671-9d36f94553a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re, nltk\n",
    "nltk.download('punkt')\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.style.use('dark_background')\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50c82a7-fba6-4e8d-ab51-f198e5d60100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a76c23-8ac8-4fbe-8c5f-964a38cf1058",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'Dataset/training.1600000.processed.noemoticon.csv'\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efee7042-1f12-4c96-b07a-0a64178e007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f4190a-7645-4849-a75d-a4ee7b3a970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2b7923-4fd9-462a-9471-d315b404c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ee559-3f9f-4869-8b16-21ed1be69f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corelation Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f450d-2ffb-4049-82bf-055b7d5cba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr , mask=np.zeros_like(corr, dtype=np.bool) , cmap=sns.diverging_palette(-100,0,as_cmap=True) , square = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ee494-f581-4da8-b388-0a3e13928679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afef7d64-0cb5-4390-92cf-9e4b496dd4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_data = df[['1467810369', 'Mon Apr 06 22:19:45 PDT 2009', 'NO_QUERY','_TheSpecialOne_',]]\n",
    "df = df.drop(columns=unused_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0be93c-b3e3-4f1f-9aef-9b8e25b32e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename (columns= {'0': 'Sentiment'}, inplace=True)\n",
    "df.rename (columns= {\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\": 'Text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8051526-58b0-4ae4-bf5a-6d073be6ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441529d3-3cc0-45d4-a53e-0047c6931d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9020f-9920-4909-bc0d-96c50fa34e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_map = {0: \"negative\", 4:\"positive\"}\n",
    "\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]\n",
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: decode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf99589a-d18c-4e95-938a-cc73714a1108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516b0203-87c6-4cc6-8229-4ba05e8cfc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20)) # Positive Sentiment\n",
    "plt.grid(False)\n",
    "wc = WordCloud(width = 1600 , height = 800 , max_words = 3000).generate(\" \".join(df[df.Sentiment == 'negative'].Text))\n",
    "plt.imshow(wc , interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339e85d3-ea13-4967-949f-ca334d9efc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20)) # Positive Sentiment\n",
    "plt.grid(False)\n",
    "wc = WordCloud(width = 1600 , height = 800 , max_words = 3000).generate(\" \".join(df[df.Sentiment == 'positive'].Text))\n",
    "plt.imshow(wc , interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3117d20-7647-4d5a-aefb-86d503faf03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68400beb-32a2-45bb-924d-6846bdf21910",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "sns.countplot(x = \"Sentiment\" , data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d25eb0e-d935-4826-bec8-e39483e3975b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18ecb6-c551-4928-bd64-6c86fbbc723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_the_tweet(text):\n",
    "  tokens= nltk.word_tokenize(re.sub(\"[^a-zA-Z]\", \" \",text))\n",
    "  tokens = [token.lower() for token in tokens]\n",
    "  return ' '.join(tokens[2:])\n",
    "\n",
    "def text_process(msg):\n",
    "  nopunc =[char for char in msg if char not in string.punctuation]\n",
    "  nopunc=''.join(nopunc)\n",
    "  return ' '.join([word for word in nopunc.split() if word.lower() not in stopwords.words('english')])\n",
    " \n",
    "def check_scores(clf, X_train, X_test, y_train, y_test):\n",
    "  model = clf.fit(X_train, y_train)\n",
    "  predicted_class = model.predict(X_test)\n",
    "  predicted_class_train = model.predict(X_train)\n",
    "  test_probs = model.predict_proba(X_test)\n",
    "  test_probs = test_probs[:, 1]\n",
    "  yhat = model.predict(X_test)\n",
    "  lr_precision, lr_recall, _ = precision_recall_curve(y_test, test_probs)\n",
    "  lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
    "\n",
    "\n",
    "  print('Train confusion matrix is: ',)\n",
    "  print(confusion_matrix(y_train, predicted_class_train))\n",
    "  print()\n",
    "\n",
    "  print('Test confusion matrix is: ')\n",
    "  print(confusion_matrix(y_test, predicted_class))\n",
    "  print()\n",
    "\n",
    "  print(classification_report(y_test,predicted_class)) \n",
    "  print() \n",
    "\n",
    "  train_accuracy = accuracy_score(y_train,predicted_class_train)\n",
    "  test_accuracy = accuracy_score(y_test,predicted_class)\n",
    "\n",
    "  print(\"Train accuracy score: \", train_accuracy)\n",
    "  print(\"Test accuracy score: \",test_accuracy )\n",
    "  print()\n",
    "  \n",
    "  train_auc = roc_auc_score(y_train, clf.predict_proba(X_train)[:,1])\n",
    "  test_auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "  print(\"Train ROC-AUC score: \", train_auc)\n",
    "  print(\"Test ROC-AUC score: \", test_auc)\n",
    "  fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "  ax1.plot(lr_recall, lr_precision)\n",
    "  ax1.set(xlabel=\"Recall\", ylabel=\"Precision\")\n",
    "\n",
    "  plt.subplots_adjust(left=0.5,\n",
    "                    bottom=0.1, \n",
    "                    right=1.5, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "  print()\n",
    "  print('Are under Precision-Recall curve:', lr_f1)\n",
    "  \n",
    "  fpr, tpr, _ = roc_curve(y_test, test_probs)\n",
    "\n",
    "\n",
    "  ax2.plot(fpr, tpr)\n",
    "  ax2.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "\n",
    "  print(\"Area under ROC-AUC:\", lr_auc)\n",
    "  return train_accuracy, test_accuracy, train_auc, test_auc\n",
    "\n",
    "\n",
    "\n",
    "def grid_search(model, parameters, X_train, Y_train):\n",
    "  #Doing a grid\n",
    "  grid = GridSearchCV(estimator=model,\n",
    "                       param_grid = parameters,\n",
    "                       cv = 2, verbose=2, scoring='roc_auc')\n",
    "  #Fitting the grid \n",
    "  grid.fit(X_train,Y_train)\n",
    "  print()\n",
    "  print()\n",
    "  # Best model found using grid search\n",
    "  optimal_model = grid.best_estimator_\n",
    "  print('Best parameters are: ')\n",
    "  print( grid.best_params_)\n",
    "\n",
    "  return optimal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64c2d1-68ee-4fdc-9dea-aa4291624799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb38a2b3-c82a-4fb5-abcc-2d5bd4ef1992",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_tweet'] = df['Text'].apply(clean_the_tweet)\n",
    "\n",
    "df.head()\n",
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: 1 if x =='positive' else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b44d6-10aa-4c27-ad81-a84084ea6bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bdadc6-5723-4271-ad85-2acad49db20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True, lowercase=True)\n",
    "X_tf_idf= vectorizer.fit_transform(df.cleaned_tweet)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_tf_idf, df['Sentiment'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c519893-df8b-44e2-b81f-8c226af4f922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abacadb5-de90-40aa-9801-32821c50e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [df['cleaned_tweet'][i] for i in range( len(df))]\n",
    "\n",
    "voc_size=5000\n",
    "\n",
    "onehot_=[one_hot(words,voc_size)for words in corpus] \n",
    "\n",
    "max_sent_length=max([len(i) for i in corpus])\n",
    "\n",
    "embedded_docs=pad_sequences(onehot_,padding='pre',maxlen=max_sent_length)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(512, input_dim = max_sent_length, activation='sigmoid'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "X_final=np.array(embedded_docs)\n",
    "y_final=np.array(df['Sentiment'])\n",
    "X_final.shape, y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66f44f-7200-4722-98df-da6bda837b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_NN, X_test_NN, y_train_NN, y_test_NN = train_test_split(X_final, y_final, test_size=0.3, random_state=42)\n",
    "model.fit(X_train_NN, y_train_NN, validation_data = (X_test_NN, y_test_NN), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b38d2-8d20-45fe-852c-6e342768e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_NN=np.round(model.predict(X_test_NN))\n",
    "y_train_pred_NN=np.round(model.predict(X_train_NN))\n",
    "y_test_pred_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721641b0-ac41-4856-ad37-32b0ecc1c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_NN = accuracy_score(y_test_NN, y_test_pred_NN)\n",
    "train_acc_NN = accuracy_score(y_train_NN, y_train_pred_NN)\n",
    "test_roc_NN = roc_auc_score(y_test_NN, y_test_pred_NN)\n",
    "train_roc_NN = roc_auc_score(y_train_NN, y_train_pred_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eeea57-134b-4c35-a819-bc5e1ae1ddb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95c8155-ccc7-4dec-a9cd-8c73a8e0b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [df['cleaned_tweet'][i] for i in range( len(df))]\n",
    "\n",
    "voc_size=5000\n",
    "\n",
    "onehot_=[one_hot(words,voc_size)for words in corpus] \n",
    "\n",
    "max_sent_length=max([len(i) for i in corpus])\n",
    "\n",
    "embedded_docs=pad_sequences(onehot_,padding='pre',maxlen=max_sent_length)\n",
    "    \n",
    "embedding_vector_features=64\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=max_sent_length))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "X_final=np.array(embedded_docs)\n",
    "y_final=np.array(df['Sentiment'])\n",
    "X_final.shape,y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e1d1e-65ad-41e9-a68c-e4a12cc4ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LSTM, X_test_LSTM, y_train_LSTM, y_test_LSTM = train_test_split(X_final, y_final, test_size=0.3, random_state=42)\n",
    "model.fit(X_train_LSTM, y_train_LSTM, validation_data = (X_test_LSTM, y_test_LSTM), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ed60a-5cb4-45a6-a95b-720e0c08f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_LSTM=np.round(model.predict(X_test_LSTM))\n",
    "y_train_pred_LSTM=np.round(model.predict(X_train_LSTM))\n",
    "y_test_pred_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee37fe65-5072-4625-859f-654fe20840a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_LSTM = accuracy_score(y_test_LSTM, y_test_pred_LSTM)\n",
    "train_acc_LSTM = accuracy_score(y_train_LSTM, y_train_pred_LSTM)\n",
    "test_roc_LSTM = roc_auc_score(y_test_LSTM, y_test_pred_LSTM)\n",
    "train_roc_LSTM = roc_auc_score(y_train_LSTM, y_train_pred_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f663695-c2b2-4aec-b476-fc50c98a0a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae6d28-3f5d-481b-b011-78908f94aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_naive_bayes = MultinomialNB()\n",
    "m_train_accuracy, m_test_accuracy, m_train_auc, m_test_auc = check_scores(m_naive_bayes ,x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89c5a89-5d22-48ad-acf7-dc9d6710d8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52287d07-ab39-4561-977c-61a645987de9",
   "metadata": {},
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "r_train_accuracy, r_test_accuracy, r_train_auc, r_test_auc= check_scores(rf, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d148e-22bc-46c3-ae5d-0bd0d1c52e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404aa475-1121-473f-8e7a-0adfb5493840",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = svm.SVC(probability=True)\n",
    "s_train_accuracy, s_test_accuracy, s_train_auc, s_test_auc = check_scores(SVM, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279bcc2-f085-4720-9013-a4b4fa97529c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a900a7-0227-414a-8e03-7111c61371dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters ={\n",
    "    \"C\":[0.001, 0.1, 1, 10],\n",
    "    \"kernel\":['linear', 'rbf', 'sigmoid', 'poly'],\n",
    "    \"gamma\":['scale', 'auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f94fc0f-e2ff-4097-87ff-21a322f51394",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_optimized = grid_search(svm.SVC(probability=True), parameters,x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e604ef4f-d4c0-4956-8cec-86a7b2bb20b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3037817e-2ed3-4708-b67f-fadf2adcdbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "so_train_accuracy, so_test_accuracy, so_train_auc, so_test_auc = check_scores(svm_optimized,x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0177b-bf48-4020-9b66-93769f4afa22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0b6e1-f267-4977-ab18-cde9c4709b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('Artificial Neural Network',train_acc_NN, test_acc_NN, train_roc_NN, test_roc_NN),\n",
    "        ('LSTM',train_acc_LSTM, test_acc_LSTM, train_roc_LSTM, test_roc_LSTM),\n",
    "        ('Multinomial Naive Bayes',m_train_accuracy, m_test_accuracy, m_train_auc, m_test_auc),\n",
    "        ('SVM', s_train_accuracy, s_test_accuracy, s_train_auc, s_test_auc),\n",
    "        ('SVM Optimized', so_train_accuracy, so_test_accuracy, so_train_auc, so_test_auc)]\n",
    "\n",
    "\n",
    "Scores_ =pd.DataFrame(data = data, columns=['Model Name','Train Accuracy', 'Test Accuracy', 'Train ROC', 'Test ROC'])\n",
    "Scores_.set_index('Model Name', inplace = True)\n",
    "\n",
    "Scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b162796b-3282-4b8b-b928-fe3c92d93ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f8ba10-a13c-40d5-8987-fe549c6f0b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d857e029-e80b-4e29-b45c-018bb7b55fff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
